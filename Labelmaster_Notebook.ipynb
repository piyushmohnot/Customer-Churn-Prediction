{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\92306\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd  # import pandas library and give it an alias of pd\n",
    "from scipy.stats import norm, kurtosis\n",
    "import seaborn as sns\n",
    "import math\n",
    "import plotly.express as px\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from datetime import timedelta, date\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBClassifier\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales1 = pd.read_excel (r'/Users/92306/OneDrive/Documents/sales1.xlsx') # old sales file\n",
    "sales2 = pd.read_excel (r'/Users/92306/OneDrive/Documents/sales2.xlsx') # any new sales data should be added or renamed as sales2.xlsx\n",
    "account = pd.read_excel (r'/Users/92306/OneDrive/Documents/account.xlsx')\n",
    "top_sellers = pd.read_excel (r'/Users/92306/OneDrive/Documents/top_selling_items.xlsx')\n",
    "contact = pd.read_excel (r'/Users/92306/OneDrive/Documents/contact.xlsx')\n",
    "#contact1 = pd.read_excel (r'/Users/92306/OneDrive/Documents/contact_features.xlsx')\n",
    "family = pd.read_excel (r'/Users/92306/OneDrive/Documents/family.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Consolidated Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5afd33cf95ff>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  sales_consolidated = sales.groupby(['customer_time'])['Quantity Ordered','Line Item Amount'].sum().reset_index()\n",
      "<ipython-input-8-5afd33cf95ff>:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  sales_consolidated1 = sales.groupby(['customer_time'])['Quantity Ordered','Line Item Amount'].sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Merging Sales Data\n",
    "sales = pd.concat([sales1,sales2])\n",
    "# Working towards new primary key Customer_time. This will be treated as a single observation\n",
    "sales[\"customer_time\"] = sales[\"Customer No\"].astype(str) + sales[\"Posting Date\"].astype(str)\n",
    "# Filtering customers having customer no empty or blank\n",
    "sales = sales[sales['Customer No'].apply(len) == 7]\n",
    "\n",
    "## Consolidating the data transaction wise (Based on customer_time)\n",
    "sales_consolidated = sales.groupby(['customer_time'])['Quantity Ordered','Line Item Amount'].sum().reset_index()\n",
    "sales_consolidated1 = sales.groupby(['customer_time'])['Quantity Ordered','Line Item Amount'].sum().reset_index()\n",
    "sales_consolidated1['Customer No'] = sales_consolidated1['customer_time'].str[:7]\n",
    "sales_consolidated1['Posting Date'] = sales_consolidated1['customer_time'].str[7:]\n",
    "sales_consolidated['Customer No'] = sales_consolidated['customer_time'].str[:7]\n",
    "sales_consolidated['Posting Date'] = sales_consolidated['customer_time'].str[7:]\n",
    "\n",
    "# Bringing next order/transaction date against the existing transaction\n",
    "\n",
    "sales_consolidated.loc[sales_consolidated['Customer No'] == sales_consolidated['Customer No'].shift(-1),'next_order_date'] = sales_consolidated['Posting Date'].shift(-1) \n",
    "sales_consolidated.loc[sales_consolidated['next_order_date'].isnull(),'next_order_date'] = pd.to_datetime('today')\n",
    "sales_consolidated['next_order_date'] = pd.to_datetime(sales_consolidated['next_order_date'])\n",
    "sales_consolidated['Posting Date']=pd.to_datetime(sales_consolidated['Posting Date'])\n",
    "\n",
    "#Computing time to order in days\n",
    "\n",
    "sales_consolidated['time_to_order'] = sales_consolidated['next_order_date'] - sales_consolidated['Posting Date']\n",
    "sales_consolidated['time_to_order'] = sales_consolidated['time_to_order']/np.timedelta64(1,'D')\n",
    "\n",
    "#Forcing the minimum order time to be 30 days\n",
    "\n",
    "sales_consolidated.loc[sales_consolidated['time_to_order'] < 30,'time_to_order'] = 30\n",
    "\n",
    "# Assigning each customer an ID and counting the number of transactions for each customer \n",
    "sales_consolidated['block'] = (sales_consolidated['Customer No'] != sales_consolidated['Customer No'].shift(1)).astype(int).cumsum()\n",
    "sales_consolidated['count'] = sales_consolidated.groupby((sales_consolidated['Customer No'] != sales_consolidated['Customer No'].shift(1)).cumsum()).cumcount()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_consolidated['cumulative_sum_time'] = sales_consolidated.groupby('Customer No')['time_to_order'].cumsum()\n",
    "sales_consolidated.loc[sales_consolidated['Customer No'] == sales_consolidated['Customer No'].shift(1),'cumulative_sum_time_shifted'] = sales_consolidated['cumulative_sum_time'].shift(1) \n",
    "sales_consolidated.loc[sales_consolidated['Customer No'] == sales_consolidated['Customer No'].shift(1),'count_shifted'] = sales_consolidated['count'].shift(1) \n",
    "sales_consolidated.loc[sales_consolidated['count'] > 1, 'expected_purchase_window'] = sales_consolidated['cumulative_sum_time_shifted']/sales_consolidated['count_shifted']\n",
    "sales_consolidated.drop(['cumulative_sum_time', 'cumulative_sum_time_shifted','count_shifted'], axis=1, inplace=True)\n",
    "\n",
    "# Setting expected purchase window = 60 for the first transaction based on the graph above\n",
    "sales_consolidated.loc[sales_consolidated['count'] == 1, 'expected_purchase_window'] = 60\n",
    "# Computing time to churn standard based on static multiplier of 4\n",
    "sales_consolidated['time_to_churn_standard'] = sales_consolidated['expected_purchase_window']*4\n",
    "\n",
    "sales_consolidated.loc[sales_consolidated['time_to_order'] < sales_consolidated['time_to_churn_standard'], 'churn_standard'] = 0\n",
    "sales_consolidated.loc[sales_consolidated['time_to_order'] >= sales_consolidated['time_to_churn_standard'], 'churn_standard'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marking last transaction for all the customer and removing single transaction customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ~sales_consolidated.duplicated(['Customer No'], keep='last')\n",
    "m2 = sales_consolidated.duplicated(['Customer No'], keep=False)\n",
    "m = m1 & m2\n",
    "sales_consolidated.loc[m, 'last'] = 'true'\n",
    "\n",
    "sales_consolidated = sales_consolidated[sales_consolidated.duplicated('block',keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Modified & Churn Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making column time to churn modified and churn modified based on modified multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_consolidated.loc[(sales_consolidated['expected_purchase_window'] > 0) & (sales_consolidated['expected_purchase_window'] <= 60), 'time_to_churn_modified'] = sales_consolidated['time_to_churn_standard']\n",
    "sales_consolidated.loc[(sales_consolidated['expected_purchase_window'] > 60) & (sales_consolidated['expected_purchase_window'] <= 120), 'time_to_churn_modified'] = sales_consolidated['expected_purchase_window']*3\n",
    "sales_consolidated.loc[(sales_consolidated['expected_purchase_window'] > 120) & (sales_consolidated['expected_purchase_window'] <= 240), 'time_to_churn_modified'] = sales_consolidated['expected_purchase_window']*2\n",
    "sales_consolidated.loc[(sales_consolidated['expected_purchase_window'] > 240), 'time_to_churn_modified'] = sales_consolidated['expected_purchase_window']\n",
    "\n",
    "sales_consolidated.loc[sales_consolidated['time_to_order'] < sales_consolidated['time_to_churn_modified'], 'churn_modified'] = 0\n",
    "sales_consolidated.loc[sales_consolidated['time_to_order'] >= sales_consolidated['time_to_churn_modified'], 'churn_modified'] = 1\n",
    "\n",
    "\n",
    "## Making churn score column. This basically tells us about the state of the customer at a particular point in time\n",
    "sales_consolidated['churn_score'] = sales_consolidated['time_to_order']/sales_consolidated['time_to_churn_standard']*100\n",
    "sales_consolidated.loc[sales_consolidated['churn_score'] > 100,'churn_score'] = 100\n",
    "\n",
    "sales_consolidated.loc[(sales_consolidated['churn_score'] < 25),'churn alarm'] = 'Normal'\n",
    "sales_consolidated.loc[(sales_consolidated['churn_score'] >= 25) & (sales_consolidated['churn_score'] < 50),'churn alarm'] = 'slightly concerning'\n",
    "sales_consolidated.loc[(sales_consolidated['churn_score'] >= 50) & (sales_consolidated['churn_score'] < 75),'churn alarm'] = 'very concerning'\n",
    "sales_consolidated.loc[(sales_consolidated['churn_score'] >=75),'churn alarm'] = 'critical'\n",
    "sales_consolidated['year'] = pd.DatetimeIndex(sales_consolidated['Posting Date']).year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account Data Merging with Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = account.rename(columns={\"AccountNumber\": \"Customer No\"})\n",
    "## Bringing accounts data information in consolidated data\n",
    "sales_account = pd.merge(sales_consolidated,\n",
    "                 account,\n",
    "                 on='Customer No', \n",
    "                 how='left')\n",
    "## Making customer wise table side by side\n",
    "sales_consolidated_lasttransaction = sales_account.loc[sales_account['last'] == 'true']\n",
    "\n",
    "### Checking Churn Rate trend CLV wise and making CLV buckets\n",
    "sales_account['cumulative_sum_revenue'] = sales_account.groupby('Customer No')['Line Item Amount'].cumsum()\n",
    "sales_account.loc[(sales_account['cumulative_sum_revenue'] < 1000), 'revenue_bucket'] = 1\n",
    "sales_account.loc[(sales_account['cumulative_sum_revenue'] >= 1000) & (sales_account['cumulative_sum_revenue'] < 2500), 'revenue_bucket'] = 2\n",
    "sales_account.loc[(sales_account['cumulative_sum_revenue'] >= 2500) & (sales_account['cumulative_sum_revenue'] <= 5000), 'revenue_bucket'] = 3\n",
    "sales_account.loc[(sales_account['cumulative_sum_revenue'] > 5000) & (sales_account['cumulative_sum_revenue'] <= 10000), 'revenue_bucket'] = 4                               \n",
    "sales_account.loc[(sales_account['cumulative_sum_revenue'] > 10000), 'revenue_bucket'] = 5\n",
    "\n",
    "###Checking Churn Rate as a function of number of transaction. \n",
    "labels_4 = ['first_quintile', 'second_quintile', 'third_quintile', 'fourth_quintile','fifth_quintile']\n",
    "sales_account['count_group'] = pd.qcut(sales_account['count'],q=[0,0.2,0.4,0.6,0.8,1],labels=labels_4)\n",
    "\n",
    "### Merging Company Revenue Ranges for better view\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == 'Under $500,000') | (sales_account['ZI_Company_Revenue_Range__c'] == '$500,000 - $1 mil.'), 'Client_revenue'] = 'Under $1mil'\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == '$1 mil. - $5 mil.') | (sales_account['ZI_Company_Revenue_Range__c'] == '$5 mil. - $10 mil.'), 'Client_revenue'] = '$1mil-$10mil'\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == '$10 mil. - $25 mil.') | (sales_account['ZI_Company_Revenue_Range__c'] == '$25 mil. - $50 mil.')| (sales_account['ZI_Company_Revenue_Range__c'] == '$50 mil. - $100 mil.'), 'Client_revenue'] = '$10mil-$100mil'\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == '$100 mil. - $250 mil.') | (sales_account['ZI_Company_Revenue_Range__c'] == '$250 mil. - $500 mil.'), 'Client_revenue'] = '$100mil-$500mil'\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == '$500,000 - $1 mil.') | (sales_account['ZI_Company_Revenue_Range__c'] == '$1 bil. - $5 bil.') , 'Client_revenue'] = '$500mil-$5bil'\n",
    "sales_account.loc[(sales_account['ZI_Company_Revenue_Range__c'] == 'Over $5 bil.'), 'Client_revenue'] = 'Over $5bil'\n",
    "\n",
    "sales_consolidated_lasttransaction = sales_account.loc[sales_account['last'] == 'true']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Top selling products Information and building Item based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sellers=top_sellers.fillna(0)\n",
    "top_sellers['total_rev'] = top_sellers['2016'] + top_sellers['2017'] + top_sellers['2018'] + top_sellers['2019'] + top_sellers['2020']+ top_sellers['2021'] + top_sellers['2022']\n",
    "top_sellers=top_sellers.fillna(0)\n",
    "\n",
    "top_sellers.loc[top_sellers['total_rev'] >= 500000, 'item_type'] = 'Platinum'\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 250000) & (top_sellers['total_rev'] < 500000), 'item_type'] = 'Gold'\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 100000) & (top_sellers['total_rev'] < 250000), 'item_type'] = 'Silver'\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 50000) & (top_sellers['total_rev'] < 100000), 'item_type'] = 'Bronze'\n",
    "top_sellers.loc[(top_sellers['total_rev'] < 50000), 'item_type'] = 'Metal'\n",
    "top_sellers.loc[top_sellers['total_rev'] >= 500000, 'Platinum'] = 1\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 250000) & (top_sellers['total_rev'] < 500000), 'Gold'] = 1\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 100000) & (top_sellers['total_rev'] < 250000), 'Silver'] = 1\n",
    "top_sellers.loc[(top_sellers['total_rev'] >= 50000) & (top_sellers['total_rev'] < 100000), 'Bronze'] = 1\n",
    "top_sellers.loc[(top_sellers['total_rev'] < 50000), 'Metal'] = 1\n",
    "top_sellers=top_sellers.fillna(0)\n",
    "top_items = top_sellers[['Row Labels','item_type','Platinum','Gold','Silver','Bronze','Metal']]\n",
    "top_items = top_items.rename(columns={\"Row Labels\": \"Item\"})\n",
    "\n",
    "#---------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx------------------------------------------#\n",
    "\n",
    "sales = pd.merge(sales,\n",
    "                 top_items,\n",
    "                 on = ('Item'), \n",
    "                 how = 'left')\n",
    "\n",
    "sales['year'] = pd.DatetimeIndex(sales['Posting Date']).year\n",
    "sales = sales[sales['Platinum'].notnull()]\n",
    "platinum_sales = sales.groupby('customer_time')['Platinum'].sum().reset_index()\n",
    "sales_account['Platinum_products'] = platinum_sales['Platinum']\n",
    "gold_sales = sales.groupby('customer_time')['Gold'].sum().reset_index()\n",
    "sales_account['Gold_products'] = gold_sales['Gold']\n",
    "Silver_sales = sales.groupby('customer_time')['Silver'].sum().reset_index()\n",
    "sales_account['Silver_products'] = Silver_sales['Silver']\n",
    "Bronze_sales = sales.groupby('customer_time')['Bronze'].sum().reset_index()\n",
    "sales_account['Bronze_products'] = Bronze_sales['Bronze']\n",
    "Metal_sales = sales.groupby('customer_time')['Metal'].sum().reset_index()\n",
    "sales_account['Metal_products'] = Metal_sales['Metal']\n",
    "\n",
    "sales_account['total_platinum_items'] = sales_account.groupby('Customer No')['Platinum_products'].cumsum()\n",
    "sales_account['total_gold_items'] = sales_account.groupby('Customer No')['Gold_products'].cumsum()\n",
    "sales_account['total_silver_items'] = sales_account.groupby('Customer No')['Silver_products'].cumsum()\n",
    "sales_account['total_Bronze_items'] = sales_account.groupby('Customer No')['Bronze_products'].cumsum()\n",
    "sales_account['total_Metal_items'] = sales_account.groupby('Customer No')['Metal_products'].cumsum()\n",
    "\n",
    "#---------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx------------------------------------------#\n",
    "\n",
    "sales_account['Platinum_Quality_Ratio'] = (sales_account['total_platinum_items'])/((sales_account['total_platinum_items'])\n",
    "                                                                                   +sales_account['total_gold_items']\n",
    "                                                                                   +sales_account['total_silver_items']\n",
    "                                                                                   +sales_account['total_Bronze_items']\n",
    "                                                                                   +sales_account['total_Metal_items'])*100\n",
    "\n",
    "sales_account['Platinum_Gold_Quality_Ratio'] = (sales_account['total_platinum_items']+sales_account['total_gold_items'])/((sales_account['total_platinum_items'])\n",
    "                                                                                   +sales_account['total_gold_items']\n",
    "                                                                                   +sales_account['total_silver_items']\n",
    "                                                                                   +sales_account['total_Bronze_items']\n",
    "                                                                                   +sales_account['total_Metal_items'])*100\n",
    "\n",
    "sales_account['Platinum_Quality_Ratio'] = sales_account['Platinum_Quality_Ratio']*100\n",
    "sales_account['Platinum_Gold_Quality_Ratio'] = sales_account['Platinum_Gold_Quality_Ratio']*100\n",
    "sales_account.loc[sales_account['total_platinum_items'] == 0, 'Platinum_bucket'] = '0'\n",
    "sales_account.loc[(sales_account['total_platinum_items'] >= 1) & (sales_account['total_platinum_items'] < 5), 'Platinum_bucket'] = '1-5'\n",
    "sales_account.loc[(sales_account['total_platinum_items'] >= 5), 'Platinum_bucket'] = '>5'\n",
    "\n",
    "sales_consolidated_lasttransaction = sales_account.loc[(sales_account['last'] == 'true')]\n",
    "\n",
    "#---------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx------------------------------------------#\n",
    "\n",
    "sales_account.loc[sales_account['Platinum_Quality_Ratio'] == 0, 'Platinum_Quality_bucket'] = '0'\n",
    "sales_account.loc[(sales_account['Platinum_Quality_Ratio'] >= 1) & (sales_account['Platinum_Quality_Ratio'] < 25), 'Platinum_Quality_bucket'] = '1-25'\n",
    "sales_account.loc[(sales_account['Platinum_Quality_Ratio'] >= 25) & (sales_account['Platinum_Quality_Ratio'] <= 100), 'Platinum_Quality_bucket'] = '>25'\n",
    "sales_consolidated_lasttransaction = sales_account.loc[(sales_account['last'] == 'true')]\n",
    "\n",
    "#---------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx------------------------------------------#\n",
    "\n",
    "first_sale = sales_account.loc[sales_account['count'] == 1][['Customer No','Posting Date']]\n",
    "first_sale = first_sale.rename(columns={\"Posting Date\": \"first_sale_date\"})\n",
    "sales_account = pd.merge(sales_account,\n",
    "                 first_sale,\n",
    "                 on=('Customer No'), \n",
    "                 how='left')\n",
    "sales_account['tenure'] = sales_account['Posting Date'] - sales_account['first_sale_date']\n",
    "sales_account['tenure'] = sales_account['tenure']/np.timedelta64(1,'D')\n",
    "sales_consolidated_lasttransaction = sales_account.loc[(sales_account['last'] == 'true')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average Quantity Ordered, Total Quantity, Gradient Quantity, Total Cost and Average Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master data set for features\n",
    "features = sales_account\n",
    "#1- Average Quantity of items ordered by the customer\n",
    "features['AvgQuantity'] = (\n",
    "    features.groupby('Customer No')['Quantity Ordered'].apply(lambda x: x.expanding().mean()))\n",
    "\n",
    "#2- Total number of items purchased by the customer till date\n",
    "features['TotalQuantity'] = (\n",
    "    features.groupby('Customer No')['Quantity Ordered'].cumsum())\n",
    "\n",
    "#3- Gradient of the number of products ordered by customer\n",
    "features['GradientQuantity'] = (\n",
    "    features.groupby('Customer No')['Quantity Ordered'].diff())\n",
    "\n",
    "#5- Total revenue generated by the customer to date/ CLV\n",
    "features['TotalCost'] = (\n",
    "    features.groupby('Customer No')['Line Item Amount'].cumsum())\n",
    "\n",
    "#6- Average revenue of the customer (Line amount/total orders) \n",
    "features['AvgCost'] = (\n",
    "    features.groupby('Customer No')['Line Item Amount'].apply(lambda x: x.expanding().mean()))\n",
    "\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "##### Net Purchasing Interval Increasing or Decreasing Variable\n",
    "sales_account.loc[sales_account['Customer No'] == sales_account['Customer No'].shift(1),'last_order_date'] = sales_account['Posting Date'].shift(1) \n",
    "sales_account['time_between_sales_trend'] = sales_account['Posting Date'] - sales_account['last_order_date']\n",
    "sales_account['time_between_sales_trend'] = sales_account['time_between_sales_trend']/np.timedelta64(1,'D')\n",
    "sales_account['time_between_sales_trend'] = (\n",
    "    sales_account.groupby('Customer No')['time_between_sales_trend'].diff())\n",
    "sales_account['time_between_sales_trend'] = (\n",
    "    sales_account.groupby('Customer No')['time_between_sales_trend'].cumsum())\n",
    "\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "\n",
    "##### Net Sales Revenue Increasing or Decreasing\n",
    "sales_account['Gradient_Revenue'] = (\n",
    "    features.groupby('Customer No')['Line Item Amount'].diff())\n",
    "sales_account['Gradient_Revenue'] = (\n",
    "    sales_account.groupby('Customer No')['Gradient_Revenue'].cumsum())\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "# Customer Specific top Items\n",
    "x=pd.DataFrame(sales.groupby(['Customer No'])['Item'].value_counts().rename('Count').reset_index()) \n",
    "x= x.drop_duplicates('Customer No')\n",
    "features =pd.merge(features, x, on=('Customer No'), how='left')\n",
    "features = features.rename(columns={'Item':'Customer_specific_pop.Item', 'Count':'Popular_item_count'})\n",
    "y = pd.DataFrame(sales.groupby(['Customer No'])['Department Dim Description'].value_counts().rename('Count').reset_index()) \n",
    "y= y.drop_duplicates('Customer No')\n",
    "features =pd.merge(features, y, on=('Customer No'), how='left')\n",
    "features = features.rename(columns={'Department Dim Description':'top_department_dims', 'Count':'popular__department_dims_count'})\n",
    "z = pd.DataFrame(sales.groupby(['Customer No'])['Product Group Description'].value_counts().rename('Count').reset_index()) \n",
    "z= z.drop_duplicates('Customer No')\n",
    "features =pd.merge(features, z, on=('Customer No'), how='left')\n",
    "features = features.rename(columns={'Product Group Description':'top_product_dims', 'Count':'popular_dims_count'})\n",
    "sales_account = features\n",
    "\n",
    "u = pd.DataFrame(sales.groupby(['Customer No','Department Dim Description'])['Item'].count().reset_index())\n",
    "u['product_lines'] = pd.DataFrame(u[['Customer No','Department Dim Description']].groupby(['Customer No'])['Department Dim Description'].transform(lambda x : ' | '.join(x)))\n",
    "u= u.drop_duplicates('Customer No')\n",
    "u.drop(['Department Dim Description','Item'], axis = 1, inplace = True) \n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "'''\n",
    "##### No. of Managers & Consolidated Silverpop score\n",
    "contact1 = contact1.rename(columns={\"AccountNumber\": \"Customer No\"})\n",
    "contact1 = contact1[['Customer No','No.Of Managers','Consolidated_Silverpop']]\n",
    "sales_account = pd.merge(sales_account,\n",
    "                 contact1,\n",
    "                 on=('Customer No'), \n",
    "                 how='left')\n",
    "'''\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "\n",
    "##### Percent DGOP contacts\n",
    "contact2 = contact.groupby('Acct_Number__c').agg(NoofContacts_DGOP=('Job_Function_LM__c', 'value_counts')).reset_index()\n",
    "contact3=contact2.groupby('Acct_Number__c').agg(TotalContacts=('NoofContacts_DGOP', 'sum')).reset_index()\n",
    "contact_DGOP=contact2.loc[(contact2['Job_Function_LM__c']==\"DG\") | (contact2['Job_Function_LM__c']==\"OP\")]\n",
    "contact_DGOP=contact_DGOP.groupby('Acct_Number__c').agg(Total_DGOP_Contacts=('NoofContacts_DGOP', 'sum')).reset_index()\n",
    "contact_DGOP=contact_DGOP.merge(contact3,on=('Acct_Number__c'),how=('left'))\n",
    "contact_DGOP['Perc_DGOP']=((contact_DGOP['Total_DGOP_Contacts'])/(contact_DGOP['TotalContacts'])*100)\n",
    "\n",
    "sales_account = sales_account.merge(contact_DGOP,left_on=('Customer No'),right_on=('Acct_Number__c'),how=('left'))\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "##### Compliance score of family and family data join with sales_account\n",
    "family['Family_Name__c'] = family['Family_Name__c'].astype(str)\n",
    "family['Family_Segmentation__c'] = family['Family_Segmentation__c'].fillna('not_compliant')\n",
    "sub ='Safely'\n",
    "sub2 = 'Basically'\n",
    "sub3 = 'not_compliant'\n",
    "family.loc[family[\"Family_Segmentation__c\"].str.contains(sub),'compliance_score'] = 1\n",
    "family.loc[family[\"Family_Segmentation__c\"].str.contains(sub2),'compliance_score'] = 2\n",
    "family.loc[family[\"Family_Segmentation__c\"].str.contains(sub3),'compliance_score'] = 3\n",
    "del family['Tier_Note__c']\n",
    "sales_account['family_code'] = sales_account['FamilyCode_FNT__c'].astype(str).str.split('.').str[0]\n",
    "sales_account = sales_account.merge(family,left_on=('family_code'),right_on=('Family_Name__c'),how=('left'))\n",
    "\n",
    "del sales_account['ZI_Industry__c']\n",
    "industry = account[['Customer No','ZI_Industry__c']]\n",
    "sales_account = sales_account.merge(industry,left_on=('Customer No'),right_on=('Customer No'),how=('left'))\n",
    "sales_account.loc[sales_account['ZI_Industry__c'].isnull(),'ZI_Industry__c'] = sales_account['Family_Industry_Description_New__c']\n",
    "sales_consolidated_lasttransaction = sales_account.loc[(sales_account['last'] == 'true')]\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "##### Item Diversity Index and Dept Diversity Index\n",
    "sales_item = sales.groupby(['customer_time'])['Item'].nunique().reset_index()\n",
    "sales_dept = sales.groupby('customer_time')['Department Dim Description'].nunique().reset_index()\n",
    "sales_item = sales_item.rename(columns={'Item': \"item_diversity_index\"})\n",
    "sales_dept = sales_dept.rename(columns={'Department Dim Description': \"dept_diversity_index\"})\n",
    "sales_account = sales_account.merge(sales_item, on = ('customer_time'),how=('left'))\n",
    "sales_account = sales_account.merge(sales_dept, on = ('customer_time'),how=('left'))\n",
    "sales_account['cumulative_item_count'] = sales_account.groupby('Customer No')['item_diversity_index'].cumsum()\n",
    "sales_account['cumulative_dept_count'] = sales_account.groupby('Customer No')['dept_diversity_index'].cumsum()\n",
    "sales_account['item_diversity_index'] = sales_account['cumulative_item_count']/sales_account['count']\n",
    "sales_account['dept_diversity_index'] = sales_account['cumulative_dept_count']/sales_account['count']\n",
    "sales_account.drop(['cumulative_item_count', 'cumulative_dept_count'], axis=1, inplace=True)\n",
    "sales_consolidated_lasttransaction = sales_account.loc[(sales_account['last'] == 'true')]\n",
    "sales_consolidated_lasttransaction =pd.merge(sales_consolidated_lasttransaction, u, on=('Customer No'), how='left')\n",
    "\n",
    "#------------------------------------xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx---------------------------------------------#\n",
    "\n",
    "### Date Churned\n",
    "sales_consolidated_lasttransaction['date_churned'] = sales_consolidated_lasttransaction['Posting Date'] +  pd.to_timedelta(sales_consolidated_lasttransaction['time_to_churn_standard'], unit='D')\n",
    "EndDate = date.today() + timedelta(days=10)\n",
    "\n",
    "\n",
    "## Output File for Marketing\n",
    "output_data = sales_consolidated_lasttransaction[['Customer No','churn_standard','date_churned','Tier__c','cumulative_sum_revenue','ZI_Industry__c',\n",
    "                                   'Perc_DGOP','product_lines','Customer_specific_pop.Item','top_product_dims',\n",
    "                                    'top_department_dims']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IIT_churn_master_dataset = sales_account\n",
    "IIT_churn_customer_master_dataset = sales_consolidated_lasttransaction\n",
    "IIT_churn_master_dataset = IIT_churn_master_dataset.drop(['Quantity Ordered','Line Item Amount','next_order_date','block',\n",
    "                       'last','year','Id_x','CreatedDate_x','LastActivityDate','FamilyCode_FNT__c',\n",
    "                       'Platinum_products','Gold_products','Silver_products','Bronze_products','Metal_products',\n",
    "                       'first_sale_date','GradientQuantity','Acct_Number__c','family_code','Id_y','CreatedDate_y',\n",
    "                       'Family_Name__c','last_order_date'],axis = 1)\n",
    "IIT_churn_customer_master_dataset = IIT_churn_customer_master_dataset.drop(['customer_time','Quantity Ordered','Line Item Amount','next_order_date','block',\n",
    "                       'last','year','Id_x','CreatedDate_x','LastActivityDate','FamilyCode_FNT__c','count_group',\n",
    "                       'Platinum_products','Gold_products','Silver_products','Bronze_products','Metal_products',\n",
    "                       'first_sale_date','GradientQuantity','Acct_Number__c','family_code','Id_y','CreatedDate_y',\n",
    "                       'Family_Name__c','last_order_date'],axis = 1)\n",
    "\n",
    "# Replacing Missing values\n",
    "IIT_churn_master_dataset['Client_revenue'] = sales_account['Client_revenue']\n",
    "IIT_churn_master_dataset['Client_revenue'].fillna('other', inplace = True)\n",
    "IIT_churn_master_dataset['Family_Industry_Description_New__c'].fillna('Unassigned', inplace = True)\n",
    "IIT_churn_master_dataset['compliance_score'].fillna(3, inplace = True)\n",
    "IIT_churn_master_dataset[\"compliance_score\"].replace({1: \"High\", 2: \"Medium\", 3:\"Low\"}, inplace=True)\n",
    "IIT_churn_master_dataset['Territory__c'].fillna('UNKNOWN', inplace = True)\n",
    "IIT_churn_master_dataset['plat_gold_per_transaction'] = (IIT_churn_master_dataset['total_platinum_items'] + IIT_churn_master_dataset['total_gold_items'])/IIT_churn_master_dataset['count']\n",
    "IIT_churn_master_dataset['Perc_DGOP'].fillna(33, inplace = True)\n",
    "\n",
    "# Making buckets of gradient rev\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Gradient_Revenue'] <= 0),'gradient_rev_direction'] = 'negative'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Gradient_Revenue'] > 0) & (IIT_churn_master_dataset['Gradient_Revenue'] < 500),'gradient_rev_direction'] = 'positive'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Gradient_Revenue'] >= 500),'gradient_rev_direction'] = 'very_positive'\n",
    "\n",
    "# Making buckets of item diversity index\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['item_diversity_index'] > 0) & (IIT_churn_master_dataset['item_diversity_index'] <= 2),'item_diversity_buckets'] = '1-2'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['item_diversity_index'] > 2) & (IIT_churn_master_dataset['item_diversity_index'] <= 4),'item_diversity_buckets'] = '2-4'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['item_diversity_index'] > 4) & (IIT_churn_master_dataset['item_diversity_index'] <= 6),'item_diversity_buckets'] = '4-6'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['item_diversity_index'] > 6) & (IIT_churn_master_dataset['item_diversity_index'] <= 8),'item_diversity_buckets'] = '6-8'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['item_diversity_index'] > 8),'item_diversity_buckets'] = '>8'\n",
    "\n",
    "# Making buckets of time between Sales\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['time_between_sales_trend'] < -50) ,'time_between_sales_trend_buckets'] = '<-30'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['time_between_sales_trend'] > -50) & (IIT_churn_master_dataset['time_between_sales_trend'] <= 50),'time_between_sales_trend_buckets'] = '-30_to_30'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['time_between_sales_trend'] > 50) & (IIT_churn_master_dataset['time_between_sales_trend'] <= 100),'time_between_sales_trend_buckets'] = '30-100'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['time_between_sales_trend'] > 100),'time_between_sales_trend_buckets'] = '>100'\n",
    "\n",
    "# Making buckets of DGOP\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Perc_DGOP'] < 34 ),'Perc_DGOP_buckets'] = '<34'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Perc_DGOP'] > 34) & (IIT_churn_master_dataset['Perc_DGOP'] <= 66),'Perc_DGOP_buckets'] = '34-66'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['Perc_DGOP'] > 66),'Perc_DGOP_buckets'] = '>66'\n",
    "\n",
    "# Making buckets of dept_diversity_index\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['dept_diversity_index'] == 1),'dept_diversity_index_buckets'] = '1'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['dept_diversity_index'] > 1) & (IIT_churn_master_dataset['dept_diversity_index'] <= 1.5),'dept_diversity_index_buckets'] = '1-1.5'\n",
    "IIT_churn_master_dataset.loc[(IIT_churn_master_dataset['dept_diversity_index'] > 1.5) ,'dept_diversity_index_buckets'] = '>1.5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "IIT_churn_master_dataset_2 = IIT_churn_master_dataset.drop(['customer_time','Posting Date','time_to_order',\n",
    "                       'expected_purchase_window','time_to_churn_standard','time_to_churn_modified','churn_modified','churn_score','churn alarm',\n",
    "                       'HQ_State__c','ZI_Technologies__c','total_platinum_items','total_gold_items',\n",
    "                       'total_silver_items','total_Bronze_items','total_Metal_items','Platinum_bucket','Customer_specific_pop.Item','BDM_and_Inside_Coverage__c',\n",
    "                       'ZI_Company_Revenue_Range__c','ZI_Industry__c','Family_Segmentation__c','count_group',\n",
    "                        'item_diversity_buckets','time_between_sales_trend_buckets','Perc_DGOP_buckets',\n",
    "                        'dept_diversity_index_buckets','ZI_Company_Ranking__c','ZI_Company_Employee_Range__c',\n",
    "                         'Total_DGOP_Contacts'],axis = 1)\n",
    "\n",
    "IIT_churn_master_dataset_2 = IIT_churn_master_dataset_2.rename(columns={\"Customer No\": \"customer_no\"})##Imputing Missing Values\n",
    "\n",
    "IIT_churn_master_dataset_2['ZI_Company_Type__c'].fillna('Unknown', inplace = True)\n",
    "IIT_churn_master_dataset_2['ZI_Number_Of_Locations__c'].fillna(IIT_churn_master_dataset_2['ZI_Number_Of_Locations__c'].mode()[0], inplace = True)\n",
    "IIT_churn_master_dataset_2['Gradient_Revenue'].fillna(0, inplace = True)\n",
    "IIT_churn_master_dataset_2['time_between_sales_trend'].fillna(0, inplace = True)\n",
    "IIT_churn_master_dataset_2['gradient_rev_direction'].fillna('Unknown', inplace = True)\n",
    "IIT_churn_master_dataset_2['TotalContacts'].fillna(IIT_churn_master_dataset_2['TotalContacts'].mode()[0], inplace = True)\n",
    "IIT_churn_master_dataset_2['Popular_item_count'].fillna(0, inplace = True)\n",
    "IIT_churn_master_dataset_2['item_diversity_index'].fillna(0, inplace = True)\n",
    "IIT_churn_master_dataset_2['Coverage_Priority__c'].fillna('Uncovered', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-ddb77808885b>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['last'] = sales_account['last']\n"
     ]
    }
   ],
   "source": [
    "IIT_churn_master_dataset_2['Coverage_Priority__c'] = IIT_churn_master_dataset_2['Coverage_Priority__c'].astype('category')\n",
    "IIT_churn_master_dataset_2['ZI_Company_Type__c'] = IIT_churn_master_dataset_2['ZI_Company_Type__c'].astype('category')\n",
    "IIT_churn_master_dataset_2['Platinum_Quality_bucket'] = IIT_churn_master_dataset_2['Platinum_Quality_bucket'].astype('category')\n",
    "IIT_churn_master_dataset_2['Family_Industry_Description_New__c'] = IIT_churn_master_dataset_2['Family_Industry_Description_New__c'].astype('category')\n",
    "IIT_churn_master_dataset_2['Territory__c'] = IIT_churn_master_dataset_2['Territory__c'].astype('category')\n",
    "IIT_churn_master_dataset_2['compliance_score'] = IIT_churn_master_dataset_2['compliance_score'].astype('category')\n",
    "\n",
    "train = IIT_churn_master_dataset_2[['Coverage_Priority__c', 'ZI_Company_Type__c','count',\n",
    "       'ZI_Number_Of_Locations__c', 'cumulative_sum_revenue', \n",
    "       'Platinum_Gold_Quality_Ratio','tenure', 'AvgCost', 'AvgQuantity','Popular_item_count', 'No.Of Managers',\n",
    "       'Consolidated_Silverpop', 'TotalContacts', 'Perc_DGOP',\n",
    "       'Family_Industry_Description_New__c', 'Territory__c',\n",
    "       'compliance_score', 'Gradient_Revenue', 'time_between_sales_trend',\n",
    "       'item_diversity_index', 'Client_revenue',\n",
    "       'plat_gold_per_transaction','customer_no','churn_standard','Tier__c']]\n",
    "\n",
    "train['last'] = sales_account['last']\n",
    "IIT_churn_customer_master_dataset_2 = train.loc[(train['last'] == 'true')]\n",
    "IIT_churn_customer_master_dataset_2=IIT_churn_customer_master_dataset_2.drop(['last'],axis = 1)\n",
    "train=train.drop(['last'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transaction_final_data = train\n",
    "customer = IIT_churn_customer_master_dataset_2\n",
    "customer = customer.reset_index(drop=True)\n",
    "\n",
    "#Transaction_final_data=Transaction_final_data.drop(['Unnamed: 0','Unnamed: 0.1'],axis = 1)\n",
    "#customer=customer.drop(['Unnamed: 0.1','Unnamed: 0'],axis = 1)\n",
    "#output_data.drop('Unnamed: 0',axis = 1, inplace = True)\n",
    "output_data = output_data.rename(columns={\"Customer No\": \"customer_no\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical Variables\n",
    "df3 = Transaction_final_data[['Coverage_Priority__c', 'ZI_Company_Type__c', 'Family_Industry_Description_New__c',\n",
    "       'Territory__c', 'Client_revenue','compliance_score']].copy()\n",
    "\n",
    "one_hot_encoded_data = pd.get_dummies(df3)\n",
    "\n",
    "## Numerical Variables\n",
    "df2 = Transaction_final_data[['count', 'ZI_Number_Of_Locations__c', 'cumulative_sum_revenue',\n",
    "       'Platinum_Gold_Quality_Ratio', 'tenure','AvgCost','AvgQuantity','Popular_item_count',\n",
    "        'Perc_DGOP','Gradient_Revenue','time_between_sales_trend',\n",
    "        'item_diversity_index','plat_gold_per_transaction','customer_no']].copy()\n",
    "\n",
    "tiers_exclude = ['GOV','','DISTST','GOVCON']\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_scaled= pd.DataFrame(ss.fit_transform(df2.drop('customer_no', axis=1)))\n",
    "x_scaled.columns = df2.drop('customer_no', axis=1).columns\n",
    "x_transaction = pd.concat([x_scaled, one_hot_encoded_data, Transaction_final_data['customer_no'],Transaction_final_data['churn_standard'],Transaction_final_data['Tier__c']], axis=1)\n",
    "x_transaction = x_transaction[~x_transaction.Tier__c.isin(tiers_exclude)]\n",
    "x_transaction = x_transaction.drop('Tier__c', axis=1)\n",
    "y_transaction = x_transaction['churn_standard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical Variables\n",
    "df1 = customer[['Coverage_Priority__c', 'ZI_Company_Type__c', 'Family_Industry_Description_New__c',\n",
    "       'Territory__c', 'Client_revenue','compliance_score']].copy()\n",
    "\n",
    "one_hot_encoded_data_c = pd.get_dummies(df1)\n",
    "\n",
    "## Numerical Variables\n",
    "df4 = customer[['count', 'ZI_Number_Of_Locations__c', 'cumulative_sum_revenue',\n",
    "       'Platinum_Gold_Quality_Ratio', 'tenure','AvgCost','AvgQuantity','Popular_item_count',\n",
    "        'Perc_DGOP','Gradient_Revenue','time_between_sales_trend',\n",
    "        'item_diversity_index','plat_gold_per_transaction','customer_no']].copy()\n",
    "\n",
    "x_scaled_c= pd.DataFrame(ss.fit_transform(df4.drop('customer_no', axis=1)))\n",
    "x_scaled_c.columns = df4.drop('customer_no', axis=1).columns\n",
    "x_transaction_c = pd.concat([x_scaled_c, one_hot_encoded_data_c, customer['Tier__c'],customer['customer_no'],customer['churn_standard']], axis=1)\n",
    "x_transaction_c = x_transaction_c[~x_transaction_c.Tier__c.isin(tiers_exclude)]\n",
    "x_transaction_c = x_transaction_c.drop('Tier__c', axis=1)\n",
    "y_transaction_c = x_transaction_c['churn_standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Columns\n",
    "x_transaction_c = x_transaction_c.rename(columns={\"count\":\"Count_Of_Transactions\",\"ZI_Number_Of_Locations__c\":\"Number_of_Locations\",\"cumulative_sum_revenue\":\"Cumulative_Sum_Of_Revenue\",\"tenure\":\"Customer_Tenure\",\"AvgCost\":\"Average_Cost_Of_Transactions\",\"AvgQuantity\":\"Average_Quantity_Of_Items\",\"Popular_item_count\":\"Count_Of_Popular_Items\",\"Consolidated_Silverpop\":\"Consolidated_Customer_Silver_Pop_Score\",\"Perc_DGOP\":\"Percentage_Of_DG_OP_Contacts\",\"Gradient_Revenue\":\"Change_In_Revenue\",\"time_between_sales_trend\":\"Duration_Between_Transactions\",\"item_diversity_index\":\"Index_for_Item_Diversity\",\"plat_gold_per_transaction\":\"Platinum_and_Gold_Items_per_Transactions\",\"Coverage_Priority__c_Amazon\":\"Coverage_Priority_for_Amazon\",\"Coverage_Priority__c_BDM\":\"Coverage_Priority_for_BDM\",\"Coverage_Priority__c_Distributor\":\"Coverage_Priority_for_Distributor\",'Coverage_Priority__c_Government':'Coverage_Priority_for_Government','Coverage_Priority__c_Government Contractor':'Coverage_Priority_for_Government_Contractor','Coverage_Priority__c_Inside Sales':'Coverage_Priority_for_Inside_Sales','Coverage_Priority__c_Internal Customer':'Coverage_Priority_for_Internal_Customer','Coverage_Priority__c_Spacemaster':'Coverage_Priority_for_Spacemaster','Coverage_Priority__c_Strategic Distributor':'Coverage_Priority_for_Strategic_Distributor','Coverage_Priority__c_Uncovered':'Coverage_Priority_for_Uncovered','ZI_Company_Type__c_EDUCATION':'Company_Type_as_EDUCATION','ZI_Company_Type__c_GOVERNMENT':'Company_Type_as_GOVERNMENT','ZI_Company_Type__c_NPO':'Company_Type_as_NPO','ZI_Company_Type__c_OTHER':'Company_Type_as_OTHER','ZI_Company_Type__c_PRIVATE':'Company_Type_as_PRIVATE','ZI_Company_Type__c_PUBLIC':'Company_Type_as_PUBLIC','ZI_Company_Type__c_Private':'Company_Type_as_Private','ZI_Company_Type__c_Unknown':'Company_Type_as_UNKNOWN','Family_Industry_Description_New__c_Agriculture & Food':'Family_Industry_as_Agriculture_&_Food','Family_Industry_Description_New__c_Automotive':'Family_Industry_as_Automotive','Family_Industry_Description_New__c_Aviation & Aerospace':'Family_Industry_as_Aviation_&_Aerospace','Family_Industry_Description_New__c_Chemical':'Family_Industry_as_Chemical','Family_Industry_Description_New__c_Education':'Family_Industry_as_Education','Family_Industry_Description_New__c_Gov & Military':'Family_Industry_as_Govt_&_Military','Family_Industry_Description_New__c_Mining Oil & Gas':'Family_Industry_as_MiningOil_&_Gas','Family_Industry_Description_New__c_Other':'Family_Industry_as_Other','Family_Industry_Description_New__c_Other Manufacturing':'Family_Industry_as_Other_Manufacturing','Family_Industry_Description_New__c_Pharma & Healthcare':'Family_Industry_as_Pharma_&_Healthcare','Family_Industry_Description_New__c_Retail Trade':'Family_Industry_as_Retail_Trade','Family_Industry_Description_New__c_Services':'Family_Industry_as_Services','Family_Industry_Description_New__c_Technology':'Family_Industry_as_Technology','Family_Industry_Description_New__c_Transport & Warehouse':'Family_Industry_as_Transport_&_Warehouse','Family_Industry_Description_New__c_Transport Equipment':'Family_Industry_as_Transport_Equipment','Family_Industry_Description_New__c_Unassigned':'Family_Industry_as_Unassigned','Family_Industry_Description_New__c_WasteManagement':'Family_Industry_as_Waste_Management','Family_Industry_Description_New__c_Wholesale Trade':'Family_Industry_as_Wholesale_Trade','Territory__c_CANADA':'Territory_CANADA','Territory__c_GREAT LAKES':'Territory_GREAT_LAKES','Territory__c_MIDWEST':'Territory_MIDWEST','Territory__c_Mid-Atlantic':'Territory_MID_ATLANTIC','Territory__c_NORTHEAST':'Territory_NORTHEAST', 'Territory__c_SOUTHEAST':'Territory_SOUTHEAST','Territory__c_UNKNOWN':'Territory_UNKNOWN','Territory__c_WEST':'Territory_WEST','Client_revenue_$100mil-$500mil':'Client_Revenue_Range_$100mil-$500mil','Client_revenue_$10mil-$100mil':'Client_Revenue_Range_$10mil-$100mil','Client_revenue_$1mil-$10mil':'Client_Revenue_Range_$1mil-$10mil','Client_revenue_$500mil-$5bil':'Client_Revenue_Range_$500mil-$5bil','Client_revenue_Over $5bil':'Client_Revenue_Range_Over_$5bil','Client_revenue_Under$1mil':'Client_Revenue_Range_Under$1mil','Client_revenue_other':'Client_Revenue_Range_Other','compliance_score_High':'Compliance_Score_as_High', 'compliance_score_Low':'Compliance_Score_as_Low','compliance_score_Medium':'Compliance_Score_as_Medium'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-2e6c2f3e9b7a>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_transaction.drop(['churn_standard'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_transaction_c,y_transaction_c, test_size=0.1,random_state=10, stratify=y_transaction_c)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.222, random_state=11, stratify=y_train)\n",
    "# Creating training set from transaction wise data\n",
    "X_train_transaction = x_transaction[x_transaction['customer_no'].isin(X_train['customer_no'])]\n",
    "y_train_transaction = X_train_transaction['churn_standard']\n",
    "\n",
    "X_train = X_train.dropna()\n",
    "X_val = X_val.dropna()\n",
    "X_test = X_test.dropna()\n",
    "y_train = X_train['churn_standard']\n",
    "y_val = X_val['churn_standard']\n",
    "y_test = X_test['churn_standard']\n",
    "\n",
    "X_train_transaction.drop(['churn_standard'], axis=1, inplace=True)\n",
    "X_train.drop(['churn_standard'], axis=1, inplace=True)\n",
    "X_val.drop(['churn_standard'], axis=1, inplace=True)\n",
    "X_test.drop(['churn_standard'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\92306\\anaconda3\\lib\\site-packages\\xgboost\\data.py:200: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\92306\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Implementing XGBoosting and Gradient boosting with hyperparameter tuning\n",
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=6 , use_label_encoder =False,\n",
    "    eval_metric='logloss',\n",
    "    learning_rate = 0.1,\n",
    "    gamma = 0.9\n",
    ")\n",
    "\n",
    "X_train_c = X_train.loc[:, X_train.columns != 'customer_no']\n",
    "X_val_c = X_val.loc[:, X_val.columns != 'customer_no']\n",
    "X_test_c = X_test.loc[:, X_test.columns != 'customer_no']\n",
    "clf = estimator.fit(X_train_c, y_train)\n",
    "\n",
    "### Validation Data\n",
    "y_pred = clf.predict(X_val_c)\n",
    "\n",
    "### Test Data\n",
    "y_pred = clf.predict(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\92306\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\92306\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## XGBOOST Data Preparation for final dataset\n",
    "\n",
    "yhat = clf.predict_proba(X_train_c)\n",
    "probs_train = yhat[:, 1]\n",
    "X_train['churn_probability_XGBoost'] = probs_train\n",
    "#X_train_xg = X_train[['customer_no','churn_probability_XGBoost']]\n",
    "\n",
    "yhat = clf.predict_proba(X_val_c)\n",
    "probs_val = yhat[:, 1]\n",
    "X_val['churn_probability_XGBoost'] = probs_val\n",
    "#X_val_xg = X_val[['customer_no','churn_probability_XGBoost']]\n",
    "\n",
    "yhat = clf.predict_proba(X_test_c)\n",
    "probs_test = yhat[:, 1]\n",
    "X_test['churn_probability_XGBoost'] = probs_test\n",
    "#X_test_xg = X_test[['customer_no','churn_probability_XGBoost']]\n",
    "\n",
    "X_train_xg = X_train[['customer_no','churn_probability_XGBoost']]\n",
    "X_val_xg = X_val[['customer_no','churn_probability_XGBoost']]\n",
    "X_test_xg = X_test[['customer_no','churn_probability_XGBoost']]\n",
    "xg_results = pd.concat([X_train_xg,X_val_xg,X_test_xg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na = X_train.dropna()\n",
    "X_val_na = X_val.dropna()\n",
    "X_test_na = X_test.dropna()\n",
    "\n",
    "X_train_sub = X_train_na[['Count_Of_Transactions','Customer_Tenure','Cumulative_Sum_Of_Revenue','Platinum_Gold_Quality_Ratio','Count_Of_Popular_Items',\n",
    "                      'Change_In_Revenue','Duration_Between_Transactions','Index_for_Item_Diversity'\n",
    "                       ,'Coverage_Priority_for_Uncovered','customer_no']]\n",
    "\n",
    "X_val_sub = X_val_na[['Count_Of_Transactions','Customer_Tenure','Cumulative_Sum_Of_Revenue','Platinum_Gold_Quality_Ratio','Count_Of_Popular_Items',\n",
    "                      'Change_In_Revenue','Duration_Between_Transactions','Index_for_Item_Diversity'\n",
    "                       ,'Coverage_Priority_for_Uncovered','customer_no']]\n",
    "\n",
    "X_test_sub = X_test_na[['Count_Of_Transactions','Customer_Tenure','Cumulative_Sum_Of_Revenue','Platinum_Gold_Quality_Ratio','Count_Of_Popular_Items',\n",
    "                      'Change_In_Revenue','Duration_Between_Transactions','Index_for_Item_Diversity'\n",
    "                       ,'Coverage_Priority_for_Uncovered','customer_no']]\n",
    "\n",
    "X_train_c = X_train_sub.loc[:, X_train_sub.columns != 'customer_no']\n",
    "X_val_c = X_val_sub.loc[:, X_val_sub.columns != 'customer_no']\n",
    "X_test_c = X_test_sub.loc[:, X_test_sub.columns != 'customer_no']\n",
    "\n",
    "logit = LogisticRegression( penalty = 'l2',max_iter = 500)\n",
    "logit = logit.fit(X_train_c, y_train)\n",
    "\n",
    "### Validation Data\n",
    "y_pred = logit.predict(X_val_c)\n",
    "\n",
    "### Test Data\n",
    "y_pred = logit.predict(X_test_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_features = X_train_c.columns.values.tolist()\n",
    "logit_coef = logit.coef_[0]\n",
    "\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train_c.columns,\n",
    "    'Importance': abs(logit.coef_[0])\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "cov_contribution = abs(X_train_c.values*logit_coef)\n",
    "cov_contribution = pd.DataFrame(cov_contribution, columns = X_train_c.columns)\n",
    "cov_contribution.drop(['Change_In_Revenue','Platinum_Gold_Quality_Ratio'], axis=1, inplace=True)\n",
    "res =cov_contribution.div(cov_contribution.sum(axis=1), axis=0)\n",
    "res = res.mul(100)\n",
    "res.drop('churn_standard' , axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results for Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub = X_train_sub.reset_index(drop=True)\n",
    "res['customer_no'] = X_train_sub['customer_no']\n",
    "yhat = logit.predict_proba(X_train_c)\n",
    "probs_train = yhat[:, 1]\n",
    "res['churn_probability_logit'] = probs_train\n",
    "\n",
    "###  val data predictions/probability\n",
    "\n",
    "cov_contribution = abs(X_val_c.values*logit_coef)\n",
    "cov_contribution = pd.DataFrame(cov_contribution, columns = X_val_c.columns)\n",
    "cov_contribution.drop(['Change_In_Revenue','Platinum_Gold_Quality_Ratio'], axis=1, inplace=True)\n",
    "res_val =cov_contribution.div(cov_contribution.sum(axis=1), axis=0)\n",
    "res_val = res_val.mul(100)\n",
    "\n",
    "X_val_sub = X_val_sub.reset_index(drop=True)\n",
    "res_val['customer_no'] = X_val_sub['customer_no']\n",
    "yhat = logit.predict_proba(X_val_c)\n",
    "probs_val = yhat[:, 1]\n",
    "res_val['churn_probability_logit'] = probs_val\n",
    "\n",
    "\n",
    "###  test data predictions/probability\n",
    "\n",
    "cov_contribution = abs(X_test_c.values*logit_coef)\n",
    "cov_contribution = pd.DataFrame(cov_contribution, columns = X_test_c.columns)\n",
    "cov_contribution.drop(['Change_In_Revenue','Platinum_Gold_Quality_Ratio'], axis=1, inplace=True)\n",
    "res_test =cov_contribution.div(cov_contribution.sum(axis=1), axis=0)\n",
    "res_test = res_test.mul(100)\n",
    "\n",
    "X_test_sub = X_val_sub.reset_index(drop=True)\n",
    "res_test['customer_no'] = X_test_sub['customer_no']\n",
    "yhat = logit.predict_proba(X_test_c)\n",
    "probs_test = yhat[:, 1]\n",
    "res_test['churn_probability_logit'] = probs_test\n",
    "\n",
    "model_results = pd.concat([res,res_val,res_test])\n",
    "model_results =pd.merge(model_results, xg_results, on=('customer_no'), how='left')\n",
    "model_results =pd.merge(model_results, output_data, on=('customer_no'), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Table to be used in power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_Of_Transactions</th>\n",
       "      <th>Customer_Tenure</th>\n",
       "      <th>Cumulative_Sum_Of_Revenue</th>\n",
       "      <th>Count_Of_Popular_Items</th>\n",
       "      <th>Duration_Between_Transactions</th>\n",
       "      <th>Index_for_Item_Diversity</th>\n",
       "      <th>Coverage_Priority_for_Uncovered</th>\n",
       "      <th>customer_no</th>\n",
       "      <th>churn_probability_logit</th>\n",
       "      <th>churn_probability_XGBoost</th>\n",
       "      <th>churn_standard</th>\n",
       "      <th>date_churned</th>\n",
       "      <th>Tier__c</th>\n",
       "      <th>cumulative_sum_revenue</th>\n",
       "      <th>ZI_Industry__c</th>\n",
       "      <th>Perc_DGOP</th>\n",
       "      <th>product_lines</th>\n",
       "      <th>Customer_specific_pop.Item</th>\n",
       "      <th>top_product_dims</th>\n",
       "      <th>top_department_dims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416406</td>\n",
       "      <td>88.984552</td>\n",
       "      <td>0.368756</td>\n",
       "      <td>0.012161</td>\n",
       "      <td>2.938137</td>\n",
       "      <td>2.164204</td>\n",
       "      <td>4.115782</td>\n",
       "      <td>0400128</td>\n",
       "      <td>0.073383</td>\n",
       "      <td>0.027979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-24 20:34:17.142844800</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>3595.24</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Facility Management | Labels | Software</td>\n",
       "      <td>DGISEXPSS</td>\n",
       "      <td>Masterform New</td>\n",
       "      <td>Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.952920</td>\n",
       "      <td>40.837464</td>\n",
       "      <td>9.860276</td>\n",
       "      <td>0.066614</td>\n",
       "      <td>1.069971</td>\n",
       "      <td>15.668578</td>\n",
       "      <td>22.544177</td>\n",
       "      <td>0348205</td>\n",
       "      <td>0.465341</td>\n",
       "      <td>0.697551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-04 07:59:59.999971200</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>33901.20</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books | Placards</td>\n",
       "      <td>IMO0027</td>\n",
       "      <td>Placard Accessories</td>\n",
       "      <td>Placards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.372399</td>\n",
       "      <td>84.798515</td>\n",
       "      <td>1.810304</td>\n",
       "      <td>0.682040</td>\n",
       "      <td>2.567718</td>\n",
       "      <td>6.769024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3055848</td>\n",
       "      <td>0.713519</td>\n",
       "      <td>0.730963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-06-14 00:00:00.000000000</td>\n",
       "      <td>TIER3-Pioneer</td>\n",
       "      <td>1181.98</td>\n",
       "      <td>Retail;Software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books | Labels | Personal Compliance</td>\n",
       "      <td>SLQMM</td>\n",
       "      <td>DOT Labels</td>\n",
       "      <td>Labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.876262</td>\n",
       "      <td>84.675970</td>\n",
       "      <td>0.789595</td>\n",
       "      <td>0.340433</td>\n",
       "      <td>0.454108</td>\n",
       "      <td>3.634402</td>\n",
       "      <td>5.229230</td>\n",
       "      <td>7001365</td>\n",
       "      <td>0.893625</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-09-22 00:00:00.000000000</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>64.10</td>\n",
       "      <td>Hospitals &amp; Physicians Clinics;Organizations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books | Placards</td>\n",
       "      <td>DOT0146</td>\n",
       "      <td>Code of Federal Regulations</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.926180</td>\n",
       "      <td>87.870709</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.343918</td>\n",
       "      <td>0.458757</td>\n",
       "      <td>0.359296</td>\n",
       "      <td>5.282761</td>\n",
       "      <td>1552759</td>\n",
       "      <td>0.889634</td>\n",
       "      <td>0.997429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-27 00:00:00.000000000</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>491.91</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Labels | Personal Compliance</td>\n",
       "      <td>WM8</td>\n",
       "      <td>Personalized Waste Lables</td>\n",
       "      <td>Labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33181</th>\n",
       "      <td>0.548982</td>\n",
       "      <td>90.712484</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.046755</td>\n",
       "      <td>1.971397</td>\n",
       "      <td>2.651950</td>\n",
       "      <td>3.716020</td>\n",
       "      <td>0266827</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-22 00:00:00.000000000</td>\n",
       "      <td>TIER4-Explorer</td>\n",
       "      <td>912.01</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books | Labels</td>\n",
       "      <td>F07LB</td>\n",
       "      <td>Forms</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33182</th>\n",
       "      <td>1.758810</td>\n",
       "      <td>89.810361</td>\n",
       "      <td>0.433152</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>3.692752</td>\n",
       "      <td>0.270953</td>\n",
       "      <td>3.983848</td>\n",
       "      <td>0405673</td>\n",
       "      <td>0.052515</td>\n",
       "      <td>0.602499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-06-09 00:00:00.000000000</td>\n",
       "      <td>TIER7</td>\n",
       "      <td>3361.33</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labels | Personal Compliance</td>\n",
       "      <td>SLB435P-00033600</td>\n",
       "      <td>Personalized Regulatory Markings</td>\n",
       "      <td>Personal Compliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33183</th>\n",
       "      <td>4.755753</td>\n",
       "      <td>84.295621</td>\n",
       "      <td>0.756173</td>\n",
       "      <td>0.411257</td>\n",
       "      <td>0.442885</td>\n",
       "      <td>4.238314</td>\n",
       "      <td>5.099997</td>\n",
       "      <td>3064355</td>\n",
       "      <td>0.878710</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-20 00:00:00.000000000</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>1137.91</td>\n",
       "      <td>Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books | Labels | Placards</td>\n",
       "      <td>IATA0205</td>\n",
       "      <td>DOT Labels</td>\n",
       "      <td>Labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33184</th>\n",
       "      <td>2.307302</td>\n",
       "      <td>92.342547</td>\n",
       "      <td>0.400234</td>\n",
       "      <td>0.012633</td>\n",
       "      <td>0.371264</td>\n",
       "      <td>0.290772</td>\n",
       "      <td>4.275249</td>\n",
       "      <td>0348447</td>\n",
       "      <td>0.064026</td>\n",
       "      <td>0.258024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-23 02:10:54.545462400</td>\n",
       "      <td>TIER8</td>\n",
       "      <td>4483.08</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>Books | Imprinted Placards | Placards</td>\n",
       "      <td>LQMR</td>\n",
       "      <td>Orange Panels &amp; Markings</td>\n",
       "      <td>Placards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>4.969212</td>\n",
       "      <td>88.973760</td>\n",
       "      <td>0.735999</td>\n",
       "      <td>0.429716</td>\n",
       "      <td>0.462764</td>\n",
       "      <td>4.428548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0241622</td>\n",
       "      <td>0.893362</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-08-06 08:28:14.117606400</td>\n",
       "      <td>TIER2-TrailBlazer</td>\n",
       "      <td>21638.44</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>Books | Facility Management | Imprinted Placar...</td>\n",
       "      <td>GSI500116</td>\n",
       "      <td>Reference Books</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33186 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count_Of_Transactions  Customer_Tenure  Cumulative_Sum_Of_Revenue  \\\n",
       "0                   1.416406        88.984552                   0.368756   \n",
       "1                   9.952920        40.837464                   9.860276   \n",
       "2                   3.372399        84.798515                   1.810304   \n",
       "3                   4.876262        84.675970                   0.789595   \n",
       "4                   4.926180        87.870709                   0.758380   \n",
       "...                      ...              ...                        ...   \n",
       "33181               0.548982        90.712484                   0.352413   \n",
       "33182               1.758810        89.810361                   0.433152   \n",
       "33183               4.755753        84.295621                   0.756173   \n",
       "33184               2.307302        92.342547                   0.400234   \n",
       "33185               4.969212        88.973760                   0.735999   \n",
       "\n",
       "       Count_Of_Popular_Items  Duration_Between_Transactions  \\\n",
       "0                    0.012161                       2.938137   \n",
       "1                    0.066614                       1.069971   \n",
       "2                    0.682040                       2.567718   \n",
       "3                    0.340433                       0.454108   \n",
       "4                    0.343918                       0.458757   \n",
       "...                       ...                            ...   \n",
       "33181                0.046755                       1.971397   \n",
       "33182                0.050125                       3.692752   \n",
       "33183                0.411257                       0.442885   \n",
       "33184                0.012633                       0.371264   \n",
       "33185                0.429716                       0.462764   \n",
       "\n",
       "       Index_for_Item_Diversity  Coverage_Priority_for_Uncovered customer_no  \\\n",
       "0                      2.164204                         4.115782     0400128   \n",
       "1                     15.668578                        22.544177     0348205   \n",
       "2                      6.769024                         0.000000     3055848   \n",
       "3                      3.634402                         5.229230     7001365   \n",
       "4                      0.359296                         5.282761     1552759   \n",
       "...                         ...                              ...         ...   \n",
       "33181                  2.651950                         3.716020     0266827   \n",
       "33182                  0.270953                         3.983848     0405673   \n",
       "33183                  4.238314                         5.099997     3064355   \n",
       "33184                  0.290772                         4.275249     0348447   \n",
       "33185                  4.428548                         0.000000     0241622   \n",
       "\n",
       "       churn_probability_logit  churn_probability_XGBoost  churn_standard  \\\n",
       "0                     0.073383                   0.027979             0.0   \n",
       "1                     0.465341                   0.697551             1.0   \n",
       "2                     0.713519                   0.730963             0.0   \n",
       "3                     0.893625                   0.996270             1.0   \n",
       "4                     0.889634                   0.997429             1.0   \n",
       "...                        ...                        ...             ...   \n",
       "33181                 0.043799                   0.463788             1.0   \n",
       "33182                 0.052515                   0.602499             0.0   \n",
       "33183                 0.878710                   0.813025             1.0   \n",
       "33184                 0.064026                   0.258024             0.0   \n",
       "33185                 0.893362                   0.073183             0.0   \n",
       "\n",
       "                       date_churned            Tier__c  \\\n",
       "0     2022-07-24 20:34:17.142844800              TIER8   \n",
       "1     2020-12-04 07:59:59.999971200              TIER8   \n",
       "2     2022-06-14 00:00:00.000000000      TIER3-Pioneer   \n",
       "3     2018-09-22 00:00:00.000000000              TIER8   \n",
       "4     2019-07-27 00:00:00.000000000              TIER8   \n",
       "...                             ...                ...   \n",
       "33181 2019-09-22 00:00:00.000000000     TIER4-Explorer   \n",
       "33182 2022-06-09 00:00:00.000000000              TIER7   \n",
       "33183 2022-02-20 00:00:00.000000000              TIER8   \n",
       "33184 2022-08-23 02:10:54.545462400              TIER8   \n",
       "33185 2022-08-06 08:28:14.117606400  TIER2-TrailBlazer   \n",
       "\n",
       "       cumulative_sum_revenue                                ZI_Industry__c  \\\n",
       "0                     3595.24                                 Manufacturing   \n",
       "1                    33901.20                                Transportation   \n",
       "2                     1181.98                               Retail;Software   \n",
       "3                       64.10  Hospitals & Physicians Clinics;Organizations   \n",
       "4                      491.91                                 Manufacturing   \n",
       "...                       ...                                           ...   \n",
       "33181                  912.01                                 Manufacturing   \n",
       "33182                 3361.33                                 Manufacturing   \n",
       "33183                 1137.91                                     Education   \n",
       "33184                 4483.08                                Transportation   \n",
       "33185                21638.44                                 Manufacturing   \n",
       "\n",
       "        Perc_DGOP                                      product_lines  \\\n",
       "0      100.000000            Facility Management | Labels | Software   \n",
       "1             NaN                                   Books | Placards   \n",
       "2             NaN               Books | Labels | Personal Compliance   \n",
       "3             NaN                                   Books | Placards   \n",
       "4      100.000000                       Labels | Personal Compliance   \n",
       "...           ...                                                ...   \n",
       "33181         NaN                                     Books | Labels   \n",
       "33182         NaN                       Labels | Personal Compliance   \n",
       "33183         NaN                          Books | Labels | Placards   \n",
       "33184   50.000000              Books | Imprinted Placards | Placards   \n",
       "33185   55.555556  Books | Facility Management | Imprinted Placar...   \n",
       "\n",
       "      Customer_specific_pop.Item                  top_product_dims  \\\n",
       "0                      DGISEXPSS                    Masterform New   \n",
       "1                        IMO0027               Placard Accessories   \n",
       "2                          SLQMM                        DOT Labels   \n",
       "3                        DOT0146       Code of Federal Regulations   \n",
       "4                            WM8         Personalized Waste Lables   \n",
       "...                          ...                               ...   \n",
       "33181                      F07LB                             Forms   \n",
       "33182           SLB435P-00033600  Personalized Regulatory Markings   \n",
       "33183                   IATA0205                        DOT Labels   \n",
       "33184                       LQMR          Orange Panels & Markings   \n",
       "33185                  GSI500116                   Reference Books   \n",
       "\n",
       "       top_department_dims  \n",
       "0                 Software  \n",
       "1                 Placards  \n",
       "2                   Labels  \n",
       "3                    Books  \n",
       "4                   Labels  \n",
       "...                    ...  \n",
       "33181                Books  \n",
       "33182  Personal Compliance  \n",
       "33183               Labels  \n",
       "33184             Placards  \n",
       "33185                Books  \n",
       "\n",
       "[33186 rows x 20 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}